% last updated in April 2002 by Antje Endemann
% Based on CVPR 07 and LNCS, with modifications by DAF, AZ and elle, 2008 and AA, 2010, and CC, 2011

\documentclass[runningheads]{llncs}
\usepackage{graphicx}
\usepackage[font=small]{caption}
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{amsmath,amssymb} % define this before the line numbering.
\usepackage{ruler}
\usepackage{color}
\usepackage{url}
\usepackage{comment}
\usepackage[width=122mm,left=12mm,paperwidth=146mm,height=193mm,top=12mm,paperheight=217mm]{geometry}
\usepackage{multirow}
\usepackage{tabularx}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\captionsetup[table]{belowskip=12pt,aboveskip=4pt}
\setlength{\floatsep}{7pt plus 2pt minus 2pt}
\setlength{\textfloatsep}{7pt plus 2pt minus 2pt}
\setlength{\intextsep}{7pt plus 2pt minus 2pt}

\begin{document}
% \renewcommand\thelinenumber{\color[rgb]{0.2,0.5,0.8}\normalfont\sffamily\scriptsize\arabic{linenumber}\color[rgb]{0,0,0}}
% \renewcommand\makeLineNumber {\hss\thelinenumber\ \hspace{6mm} \rlap{\hskip\textwidth\ \hspace{6.5mm}\thelinenumber}}
% \linenumbers \

\pagestyle{headings}
\mainmatter
\def\ECCV14SubNumber{150}  % Insert your submission number here

\title{A Motion Blur Resilient Fiducial Marker For Quadcopter Imaging} % Replace
% with your title

\titlerunning{ECCV-14 submission ID \ECCV14SubNumber}

\authorrunning{ECCV-14 submission ID \ECCV14SubNumber}

\author{Anonymous ECCV submission}
\institute{Paper ID \ECCV14SubNumber}

\maketitle

\begin{abstract}
This paper describes the design and evaluation of a binary fiducial marker
for use with low-cost quadcopters.  Fiducial markers are commonly placed
in environments to provide a reliable and unique marker conducive for
tracking and recognition.   For quadcopter applications, fiducials are
typically used for evaluating planning algorithms by allowing ground truth
positions in the scene to be detected from the quadcopter's camera. Quadcopters,
however, are subject to quick and unstable motions that can cause significant motion
blur that severely affects the detection rate of existing fiducial markers.
This motivated us to design a fiducial that is robust to motion blur. Our design
uses a series of concentric circles with the observation is that the direction
perpendicular to the motion blur direction will be unaffected by the blur and
therefore still be recognizable.  We detail the design and
detection algorithm for our fiducial and show that our marker can significantly
outperform existing fiducial markers in scenes captured with a quadcopter.
\keywords{Fiducials, Tracking, Detection using Blur}
\end{abstract}

\section{Introduction}

The recent availability of low-cost quadcopters has help to fuel significant efforts in
research focused on Unmanned Aerial Vehicles.  Navigation and planning of
these vehicles is typically performed using onboard inertial sensors and/or
vision based modules that uses visual cues in the real world\cite{Davison:2007}. 
However, to evaluate the effectiveness of navigation methods, artificial
fiducial markers are commonly introduces into the environment to provide
additional information that often serves for ground-truth
measurements(e.g.\cite{Bosnak:2012,Lim09,Klopschitz:2007})

In order to be effective, fiducial markers (or simply called, fiducials) need
to be easily detected in the scene.  There are various existing commonly
used fiducial markers 
\cite{NaimarkF02,ARToolkit02,Fiala05,Pitag13,runetag11}.
These typically take the form of binary codes arranged into rectangular grids (\cite{ARToolkit02,Fiala05})
or other geometric features arranged in unique spatial patterns
(\cite{NaimarkF02,Pitag13,runetag11}).
Figure \ref{fig:teaser} shows an example of the popular ARTag\cite{Fiala05} as
seen from a quad-copter.  One problem, however, is that low-cost quadcopters
often exhibit very quick and erratic motion.  These fast physical movements
results in motion blur in the quadcopters onboard camera.  Such motion blur has an adverse effect the
recognition of fiducial  markers.  This can be seen in Figure
\ref{fig:teaser}(b) where the ARTag cannot be recognized. This is not too surprising as most
fiducials are not explicitly designed to handle motion blur.  Compounding this
problem is the common problem of dropped video frames from the quadcopters
wireless communication module.   This means that no only is blurring
introduced, but there may be large discontinuities in the patterns position due
to missing video frames that makes tracking challenging.

To address this problem, propose a fiducial design that is robust to motion
blur and drastic drastic change in its position in successive frames.  Our
design is based on concentric circles as shown in Figure \ref{fig:fiducials}. 
The design is based on the observation that motion blur from a quadcopter tends
to be linear in nature.  As such, when our code is blurred, there is no blur in
the direction perpendicular to the direction of motion.   This allows the
signature of the fiducial to remain intact in any direction.  In addition, by
using concentric rings, we can treat them as bits allowing us to encode us
different fiducial identifiers.  As far as we are aware, this is the first work
to design a blur resistant marker.   Our experiments show that this design can
significantly outperform existing codes in the face of motion blur.

The remainder of this paper is organized as follows.   Section 2 gives an
overview of related work, focused on fiducials as well the related problem of
tracking.  Section 3 discusses the our design and detection algorithm, by first
examining the performance of existing codes under blur. Section 4 shows several
experiments using quadcopter imagery.  This is followed by a discussion and
summary in Section 5 and 6 respectively.

\begin{figure}
\includegraphics[width=\linewidth]{teaser.pdf}
\caption{Figure showing experimental setup and comparison of
output of ALVAR\cite{alvar} (for detecting ARTag) versus output of our
algorithm, in normal and blurred scene. (b) clearly shows that ALVAR is not
able to detect ARTag in blurred image while our algorithm can detect our
fiducial in blurred image (d)}
\label{fig:teaser}
\end{figure}

\section{Related Work}

Our work is related to two areas: fiducial markers and
object tracking. We will briefly discuss work done in both areas.

\textbf{Fiducials} :- Some of fiducial designs are shown in Figure
\ref{fig:previous_work}.

\begin{figure}
 \begin{subfigure}[b]{0.19\textwidth}
  \centering
  \includegraphics[width=\linewidth]{intersense.jpg}
  Intersense\cite{NaimarkF02}
 \end{subfigure}
 \begin{subfigure}[b]{0.19\textwidth}
 \centering
  \includegraphics[width=\linewidth]{pattKanji.pdf}
  ARToolkit\cite{ARToolkit02}
 \end{subfigure}
 \begin{subfigure}[b]{0.19\textwidth}
  \centering
  \includegraphics[width=\linewidth]{ARtag.jpg}
  ARTag\cite{Fiala05}
 \end{subfigure}
 \begin{subfigure}[b]{0.19\textwidth}
  \centering
  \includegraphics[width=\linewidth]{pifiducial.jpg}
  Pi-Tag\cite{Pitag13}
 \end{subfigure}
 \begin{subfigure}[b]{0.19\textwidth}
  \centering
  \includegraphics[width=\linewidth]{our_fiducial}
  Our Fiducial
 \end{subfigure}
 \caption{Various Fiducial Marker Designs}
 \label{fig:previous_work}
\end{figure}

Initially there were attempts to design a fiducial embedded with two
dimensional barcode inside a rectangular grid. One of the examples of such fiducial is,
ARToolkit\cite{ARToolkit02}, well known toolkit in Augmented Reality(AR) system. 
Kato et al.\cite{kato-artoolkit} have demonstrated the use of ARToolkit to find
the pose in video based AR conferencing system. Many AR applications used
ARToolkit due to its simplicity and efficiency. 

Fiala et al. \cite{Fiala05} developed a fiducial termed, ARTag, which is a
bi-tonal system consisting of a square border and an interior region filled
with a 6x6 grid of black or white cells. The improvement in ARTag compared to
ARToolkit was detection of corners instead of detection of lines to find
possible pattern. It proved to be more efficient than \cite{ARToolkit02} in
terms of marker recognition rate as well as the number of different patterns
which can be created. But, drawback of ARTag is, under significant amount of
motion blur, corners can not be detected, resulting in non-recognition of tag.

There were also attempts to use circular patterns instead of rectangular, as
the projective transformation of circles, i.e., conics, are invariant with
respective to point of view of camera\cite{runetag11}. Also, such patterns are
mostly distinguishable from background and generally can not be missed.

Concentric rings are reportedly used first by Gatrell et al.\cite{concentric}
for monocular pose estimation as well as object identification in space. Cho et al.
\cite{Cho:2001,Cho97fastcolor} have used multicolor rings instead of
black and white rings\cite{concentric} to increase possible number of fiducials.
These multicolor rings are used in wide area tracking in large scale
applications.

Naimark et al. \cite{NaimarkF02} have combined concentric rings and 2D bar code
in their fiducial named, Circular Data Matrix. It was beneficial in terms of
easy detection of fiducial as well as more number of fiducial patterns.

All of these fiducials are not recognizable under occlusion.
Bergamasco et al. \cite{runetag11} have divided fiducial into number of
circular dots, and arranged them in circular fashion, named as RUNE-Tag.
RUNE-tags are reportedly detectable even if 50\% of fiducial area is occluded.
Bergamasco et al. have developed another fiducial, named as Pi-Tag
\cite{Pitag13}, using cross-ratio concept. As cross-ratio is projective
invariant, the detection of Pi-tag is easier than other tags. Also, compared
to RUNE-tag, it uses remarkably less number of circular dots (12 dots instead of
minimum of 43 dots), still recognisable under occlusion.

But again problem with circular fiducials is, it is very difficult to detect
ellipses accurately under significant motion blur. So, under blur, recognition
rate of these fiducials is very low.

Zhang et al.\cite{Zhang:2002} and Claus et al. \cite{ClausF04} have done
quite comprehensive comparative study of various fiducial marker systems with
respect to processing time, recognition rate and accuracy with
respect to viewing angle and distance.

\textbf{Tracking}:-
Fiducial detection in video may be considered as tracking problem where tracked
object is fiducial itself. Visual tracking plays an important role in
surveillance, robotics, human computer interaction, and medical
imaging\cite{Yilmaz:2006}. Yilmaz et al.\cite{Yilmaz:2006} have done survey of
various tracking methods. 

Most tracking methods( \cite{Ross:2008,Wu:2009,Perez02}
\cite{Mei:2009} ) assume image sequence to be blur free. But in reality, motion
blur is inherent part of most of the videos. Wu et al.\cite{Wu:2011} have
developed BLUr-driven Tracker (BLUT) framework for tracking motion-blurred
targets. BLUT is based on the observation that although motion blurs degrade
the visual features of the target, they at the same time, provide useful cues
about the movements to help tracking.

BLUT framework successfully tracks blurred target when there is uniform motion
and the position of tracked object does not change drastically in successive
frames. But in our case, due to frequently dropping of intermediate frame, this
criterion may not be satisfied.

\section{Design of Fiducial}

We begin by first motivating the need for a new blur resistant fiducial by examining
the performance of prior fiducials under motion blur.  After this, we detail
our design as well as the detection algorithm used to find our marker in an image.

\subsection{Examining Prior Fiducials Under Motion Blur}

Before we detail the design of our fiducial, we examine the performance of two
popular fiducials under motion blur that have different designs. Specifically,
we examine ARTags\cite{Fiala05} and PiTags\cite{Pitag13}.

We scaled down ARTag as well as PiTag fiducial to size 150x150.  Then, we
blurred both fiducials at various orientations using different scales.
Figure \ref{fig:artag_pitag} shows sample blurred AR Tag and Pi-Tag. Finally, we
tried to detect ARTag using ALVAR library\cite{alvar} and Pi-Tag using\cite{ros_pitag}.
Figure \ref{fig:artag_pitag} shows ARTag and Pi-tag blurred with various blur
scales at different orientation. Table in the left side of Figure
\ref{fig:artag_pitag} shows the recognition rate (in percent) of two fiducial
markers at various blur scales. Table clearly indicates that both fiducial
markers can not handle large amount of motion blur.

\begin{minipage}[h!]{\textwidth}
\centering
 \begin{minipage}{0.7\textwidth}
\includegraphics[width=\linewidth]{artag_pitag.pdf}
%\captionof{figure}{Blurred AR Tag and Pi--tag with various blur scales}
\end{minipage}
\begin{minipage}{0.25\textwidth}
%\captionof{table}{Recognition rate of AR Tag and Pi-tag fiducial marker atvarious blur scales}
\begin{tabularx}{\textwidth}{|Y|Y|Y|}
\cline{1-3}
\tiny{Blur} & \multicolumn{2}{c|}{\tiny{Recognition Rate}} \\\cline{2-3}
 \tiny{Scale}& \tiny{AR Tag} &	\tiny{Pi-Tag} \\ \cline{1-3}
\tiny{15} & \tiny{100} & \tiny{100} \\ \cline{1-3}
\tiny{30} & \tiny{0} & \tiny{100} \\  \cline{1-3}
\tiny{35} & \tiny{0} & \tiny{19} \\ \cline{1-3}
\tiny{50} & \tiny{0} & \tiny{0} \\ \cline{1-3}
\end{tabularx}
\end{minipage}
\label{fig:artag_pitag}
\captionof{figure}{Figure showing ARTag and Pi-tag blurred with various blur
scales at different orientation. Table on the right shows the recognition rate
(in percent) of both fiducial markers at various blur scales along all blur
orientations. Table clearly indicates that both fiducial markers can not handle
large motion blur.}
\end{minipage}


\begin{comment}

\begin{minipage}{\textwidth}
  \begin{minipage}[b]{0.49\textwidth}
\captionof{table}{Recognition rate of AR Tag at various blur scales}
\centering
 \begin{tabularx}{0.75\textwidth}{|Y|Y|}
\cline{1-2}
Blur Scale & Recognition Rate(\%) \\ \cline{1-2}
30 & 100\\ \cline{1-2}
35 & 19 \\ \cline{1-2}
40 & 9 \\ \cline{1-2}
45 & 5 \\ \cline{1-2}
50 & 0 \\ \cline{1-2}
\end{tabularx}
\label{tab:ARTag_blur}
 \end{minipage}	
 \begin{minipage}[b]{0.49\textwidth} 	
\captionof{table}{Blur angle range}
\centering
\begin{tabularx}{0.75\textwidth}{|Y|Y|}
\cline{1-2}
Blur Scale & Blur Angle Range \\ \cline{1-2}
30 & 0 -- 90\\ \cline{1-2}
35 & 32 -- 58 \\ \cline{1-2}
40 & 41 -- 48 \\ \cline{1-2}
45 & 41 -- 48 \\ \cline{1-2}
50 & 44 -- 46 \\ \cline{1-2}
\end{tabularx}
\label{tab:artag_blurangle}
 \end{minipage}
\end{minipage}

From Table \ref{tab:ARTag_blur}, it can be clearly seen that performance of
ARTag drastically degrade with increase in blur scale.

We have also analysed the recognition rate along different blur orientations
(from 0 to 90 degrees) at different blur scales. We found that per blur scale,
at certain blur orientations, recognition of ARTag fails. Table shows the range
of blur angles for which we are able to recognise the ARTag at different blur
scales. From Table \ref{tab:artag_blurangle}, it can be seen that, when blur
scale is greater than 30, ARTag is not recognisable with horizontal blur
orientation(blur angle near zero degrees) as well as vertical blur
orientation(blur angle near 90 degrees).

We have performed blur simulation experiment on Pi-tag \cite{Pitag13} to find
how blur effects circular patterns. We tried to detect blurred Pi-tag using
\cite{ros_pitag}.

\begin{figure}
\begin{subfigure}[b]{0.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{detect_noblur.jpg}
  No Blur
 \end{subfigure}
 \begin{subfigure}[b]{0.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{detect_blur15.jpg}
  Blur Scale = 15
 \end{subfigure}
 \begin{subfigure}[b]{0.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{nodetect_blur20.jpg}
  Blur Scale = 20
 \end{subfigure}
 \caption{Effect of blur on detection of Pi-Tag}
 \label{fig:pitag_blur}
\end{figure}

From Figure \ref{fig:pitag_blur}, it can be seen that, Pi-tag detection
fails when blur scale is more than 15. The reason behind this is, Pi-tag
detection is based on Ellipse detection which will fail in the presence of
significant amount of blur. So, ellipse detection may not be the efficient way
to detect circular patterns under blur.
\end{comment}
We have designed a fiducial that may be thought of as a binary code.  It
contains concentric white rings of equal widths on a black background with a
blurred border. The outermost and innermost rings represent the start and end
of the code and is embedded in the fiducial; these are not considered part of
the code itself. The binary code is represented by the presence (or absence) of
rings between ``marker'' rings.

\begin{figure}
\centering
  \includegraphics[width=.22\linewidth]{newconcentric_00.pdf}
  \includegraphics[width=.22\linewidth]{newconcentric_01.pdf}
  \includegraphics[width=.22\linewidth]{newconcentric_10.pdf}
  \includegraphics[width=.22\linewidth]{newconcentric_11.pdf}
  \caption{Two bit binary coded fiducials (from left to right: binary code 00,
  binary code 01, binary code 10, binary code 11)}
  \label{fig:fiducials}
\end{figure}

Depending on which ring is present or absent, the resulting binary code will
change. The number of different patterns depends on the number of bits in the
binary code. For example, if the binary code has three bits, there will be a
maximum of three rings between``marker'' rings and we end up with eight
different patterns. Figure \ref{fig:fiducials} shows two bit binary coded
fiducials.

\subsection{Fiducial Detection Algorithm}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{blur_direction.pdf}
\caption{Figure showing how change in blur direction changes the location of
unblurred linear pattern.}
\label{fig:blur_direction}
\end{figure}

Our fiducial detection strategy is different from \cite{NaimarkF02,Pitag13} and works
under significant amount of blur.   In particular, we assume that scene motion
blur be modelled locally as a linear motion blur \cite{Moshe:2003,Moshe:2004}. 
Under this assumption, scene content perpendicular to the blur direction is 
unaffected by the blur.  Because of our circular design, this means the
perpendicular direction can be observed as a unblurred linear pattern.  Figure
\ref{fig:blur_direction} shows an example with various motion directions.

\begin{comment}
Overall flow of fiducial detection algorithm can be summarised as follows:

\begin{itemize}
  \item Apply Gabor filter on input image
  \item Find connected components in Gabor output
  \item Cluster the connected components into bounding boxes
  \item Detect code in the bounding box
  \begin{itemize}
    \item Run PCA on Gabor output in bounding box
    \item Find intensity profile along first principal component passing through
    centroid
    \item Classify the detected code by training examples
    standards.
  \end{itemize}
\end{itemize}
\end{comment}

Figure \ref{fig:overall_flow} shows the process involved in fiducial detection
process. 

\begin{figure}
\includegraphics[width=\linewidth]{overall_flow.pdf}
\caption{Overall Workflow}
\label{fig:overall_flow}
\end{figure}

\noindent\textbf{Gabor filter}: A 2D Gabor filter is a Gaussian kernel function
modulated by a sinusoidal plane wave. It is used to find high gradient patches from the
image. In our case, it will detect blur invariant sections of the fiducials. We
have applied Gabor filter for eight different orientations ($\theta = 0, 45,
90, 135, 180, 225, 270, 315$). We have used following parameters for
creating each Gabor kernel: $\lambda = 8$, $\gamma = 0.5$, $\sigma =
0.56\lambda$, $\psi = 0 \text{(for real part)}, \pi/2 \text{(for imaginary
part)}$.
Then L2 norm of outputs along all orientations is calculated and finally L2
normed image is binarized.

\noindent\textbf{Clustering}: Connected components are found from the Gabor
output.
These connected components are then clustered in hierarchical fashion, to find
the group of closely positioned patches.

\noindent\textbf{PCA}: Principal Component Analysis is done on the clustered
Gabor output. Along first principal component, intensity profile in the original image
is found. Number of transitions in the intensity profile will give us the
number of rings.

\noindent\textbf{Classification}: Each synthetic fiducial pattern is blurred
along 36 orientations (0, 10, 20, \ldots , 350) and intensity profile along first
principal component from every output is taken as training data for that
fiducial pattern. Process of creation of training data for fiducial with
code ``01'' is depicted in Figure \ref{fig:training_data}. Test pattern is matched
against training data using K-Nearest Neighbor Classifier (K=5) to output class label.

\begin{figure}[h!]
\centering
  \includegraphics[width=\linewidth]{training_data.pdf}
  \caption{Training data for the fiducial pattern with binary code ``01''}
  \label{fig:training_data}
\end{figure}

To increase classification accuracy, training data for patterns having same
number of rings is grouped together; e.g., in two bit binary coded fiducial,
training data for pattern ``01'' and ``10'' will be grouped together, In three
bit binary coded fiducial, training data for pattern “001”, “010” and “100” will
form one group while training data for pattern “110”, “011” and “101” will be
in other group, etc. Now, Depending on the number of detected rings in test
pattern, it is matched against corresponding group of training data, again
using  K-Nearest Neighbor Classifier. In this way, if we detect either zero
rings or maximum possible rings in the test pattern, there will be no need to do
further classification.

\section{Experimental Validation}
We have implemented\footnote{Code as well as experimental data will be made
online soon} our algorithm in C++ using OpenCV library.
Our code was run on a PC with Intel Core i7 processor(@3.4GHz) and 4GB RAM.

Our system has been tested on the image sequences captured from AR Drone
quadcopter. Each image sequence contains frames containing different fiducial
pattern. Sample output for each fiducial pattern is shown in Figure
\ref{fig:output0} -- Figure \ref{fig:output3}. Our detection process takes
around 0.3 seconds and can handle three to four frames per second.

\begin{figure}
\begin{subfigure}{0.5\textwidth}
\centering
  \includegraphics[width=\linewidth]{output_00.jpg}
  \caption{Binary code ``00''}
  \label{fig:output0}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\centering
  \includegraphics[width=\linewidth]{output_01.jpg}
  \caption{Binary code ``01''}
  \label{fig:output1}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\centering
  \includegraphics[width=\linewidth]{output_10.jpg}
  \caption{Binary code ``10''}
  \label{fig:output2}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\centering
  \includegraphics[width=\linewidth]{output_11.jpg}
  \caption{Binary code ``11''}
  \label{fig:output3}
  \end{subfigure}
  \caption{Sample Outputs for two bit binary coded fiducials}
\end{figure}

Our system has also been tested on images containing multiple fiducial patterns
in the same frame. Our algorithm successfully detected all fiducial patterns as
well as correctly classified them as shown in Figure \ref{fig:output_all}.
\begin{figure}
\centering
  \includegraphics[width=.8\linewidth]{output_all_2.jpg}
  \caption{Sample output containing all two bit binary coded fiducial patterns}
  \label{fig:output_all}
\end{figure}

\subsection{Comparison}
We will compare our results with standard fiducials such as ARTag. Also, we will
compare our results with Blur driven tracker(BLUT)\cite{Wu:2011}.
\subsubsection{Comparison with ARTag}
First, we have repeated blur simulation experiment on our fiducials too, i.e.,
we have downsized our fiducial to size 150x150 and blurred it along various
orientations with different blur scales. Then, we tried to detect the patterns
using algorithm presented in earlier section. The comparison of recognition
rate is shown in Figure \ref{fig:recognition_rate}.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{recognition_rate.png}
\caption{Comparison of recognition rate of AR Tag and our fiducials on
blur simulated data at various blur scales. It can be clearly seen that except
fiducial with binary code ``00'', our fiducial patterns are 
recognised all times.}
\label{fig:recognition_rate}
\end{figure}

Later, we recorded the real data using AR Drone quadcopter. In our experimental
setup, we have kept our fiducial along with two AR Tags, to compare the
resilience of blur by each fiducial type. We have used ar\_track\_alvar, ROS
Wrapper for ALVAR library \cite{ros_alvar}, to detect AR Tags from the stream
captured through quadcopter. In each test dataset, we used different two bit
binary coded fiducial and recorded video of around two minute duration (i.e.,
around 1000 frames) The comparison of recognition rate is shown in Table
\ref{tab:recongition_accuracy}. Classification accuracy of all fiducials (ARTag
as well as ours) is almost 100\%.

\begin{table}
\caption{Comparison of recognition rate of AR Tag and our fiducials on real
data captured through AR Drone. Each row shows analysis of a test
dataset captured for our fiducial with different binary code embedded in it}
\centering
\begin{tabularx}{0.8\textwidth}{|Y|Y|Y|Y|}
\cline{1-4}
\multirow{2}{*}{Test Dataset ID} & \multirow{2}{*}{Binary Code}
&\multicolumn{2}{c|}{Recognition Rate (\%)} \\ \cline{3-4} 
& & Our Fiducial & AR Tag\\\cline{1-4} 
1 & 00 & 86.5 &  65.6 \\ \cline{1-4} 
2 & 01 & 94.1 &  61.9 \\ \cline{1-4} 
3 & 10 & 92.74 & 62.4 \\ \cline{1-4}
4 & 11 & 93.54 & 60.3 \\ \cline{1-4}
\end{tabularx}
\label{tab:recongition_accuracy}
\end{table}

\subsubsection{Comparison with BLUT}
We have used sample image sequence (consisting of 20 frames) to test the
performance of BLUT\cite{Wu:2011} and compare it with our result on the same
image sequence. From Figure \ref{fig:BLUT_output}, it can be inferred that BLUT
is able to track the fiducial when the position of fiducial does not change too
much in successive frames. Also, it can be seen that, once BLUT looses the
track of the fiducial, it is not able to recover from that. But, our algorithm
is able to track the fiducial irrespective of the change in the position of the
fiducial in the image as shown in Figure \ref{fig:our_output}.

\begin{figure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{11.jpg}
\end{subfigure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{12.jpg}
\end{subfigure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{13.jpg}
\end{subfigure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{14.jpg}
\end{subfigure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{15.jpg}
\end{subfigure}
\caption{Output of BLUT on sample image sequence. It can be seen that from third
frame, BLUT looses the track of our fiducial}
\label{fig:BLUT_output}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{output11.jpg}
\end{subfigure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{output12.jpg}
\end{subfigure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{output13.jpg}
\end{subfigure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{output14.jpg}
\end{subfigure}
\begin{subfigure}[b]{.19\textwidth}
\includegraphics[width=\linewidth]{output15.jpg}
\end{subfigure}
\caption{Output of our algorithm on image sequence used in
Figure \ref{fig:BLUT_output}. Our algorithm is able to detect our fiducial in
all frames.}
\label{fig:our_output}
\end{figure}

\section{Discussion}

\noindent\textbf{Processing Time} :-  Currently our processing time (0.3 seconds
per frame) makes it difficult to do the fiducial detection in real-time. When we have
done the code profiling, we found that Gabor filter takes most of the time (0.03
-- 0.04 seconds per orientation). As we are applying Gabor filter along eight
orientations, we should think of some optimized way to do filtering.
Alternatively, some replacement for Gabor filter needs to be find out.  

\noindent\textbf{False Negatives} :- We found that sometime our detection
algorithm is failed do recognize our fiducial with binary code ``00'' when there is large
amount of blur. This is the reason behind lower recognition rate of ``00''
coded fiducial compared to that of our other fiducial patterns. When we
investigated the problem, we found that, if there is too much blur, in Gabor
output, the innermost ring is unable to give any response along the direction
perpendicular to blur direction. This problem can be resolved by increasing
radius of innermost ring, reducing effect of blur on the innermost ring.

\noindent\textbf{Pose Estimation} :- Currently, we are not finding the pose from
the fiducial marker. But, if we put multiple markers (at least four) in the same
scene, we may be able to find the pose. The current resolution of onboard camera
will be main hurdle to clear before we can effectively use multiple markers in
each scene.

\noindent\textbf{Number of Fiducials} :- Currently, compared to AR Tag fiducial
markers, we are able to generate less number of fiducials. Many applications in
robotics (e.g. quadcopter navigation) may not require large number of fiducial
markers as AR Tag. Most of the time, it is sufficient to have 4-6
different fiducial patterns. Still, we may be able to generate more number of
fiducials by using color background instead of black. E.g., if we just use Red,
Green and Blue as background color, number of fiducials will be increased by
factor of three.

\section{Conclusion and Future Work}
Quadcopters are subject to quick and unstable motions that can cause significant
motion blur in the captured images. It severely affects the detection rate of
existing fiducial markers. We proposed the design of a fiducial that is robust
to motion blur. Our design of contrasting concentric rings is based on the the
observation that the direction perpendicular to the motion blur direction will
be unaffected by the blur and therefore still be recognizable. We have shown
through experimental validation that our fiducial will work under significant
amount of motion blur. When compared to popular fiducials, our fiducial can
withstand around twice the amount of blur.  Though, currently we are not able to
find the pose using single pattern, we may be able to overcome this
shortcoming by using multiple markers in single scene. Also, through faster
implementation of Gabor filter, the fiducial detection can be done in realtime.

\bibliographystyle{splncs}
\bibliography{egbib}

\end{document}

